%	草稿练习
\documentclass[hyperref]{ctexart}
\usepackage[left=2.50cm, right=2.50cm, top=2.50cm, bottom=2.50cm]{geometry} %页边距
\usepackage{helvet}
\usepackage{amsmath, amsfonts, amssymb} % 数学公式、符号
\usepackage[english]{babel}
\usepackage{graphicx}   % 图片
\usepackage{url}        % 超链接
\usepackage{bm}         % 加粗方程字体
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{cite}
\bibliographystyle{IEEEtran}
\graphicspath{{figures/}}
%\renewcommand{\algorithmicrequire}{ \textbf{Input:}}       
%\renewcommand{\algorithmicensure}{ \textbf{Initialize:}} 
%\renewcommand{\algorithmicreturn}{ \textbf{Output:}}     
%算法格式
\usepackage{fancyhdr} %设置页眉、页脚
%\pagestyle{fancy}
%\lhead{}
%\chead{}
%\lfoot{}
%\cfoot{}
%\rfoot{}
\usepackage{hyperref} %bookmarks
%\hypersetup{colorlinks, bookmarks} %unicode, unicode
\usepackage{multicol}
\usepackage{caption}
\title{\textbf{基于深度学习的二维人体姿态估计综述}}
\author{谢唯嘉 6120210299 2021级}
\date{}
\begin{document}
	\maketitle
	%\captionsetup[figure]{labelfont={bf},labelformat={default},labelsep=period,name={Fig.}}
	\captionsetup[figure]{labelfont={bf},labelformat={default},labelsep=period,name={图}}
	\renewcommand\tablename{表}
	\noindent{\bf 摘要: }人体姿态估计由于其广泛的应用，近年来受到了广泛的关注真实的世界。随着最先进的人体姿态估计方法的性能不断提高通过深度学习，本文对基于深度学习的人体姿态估计进行了全面的研究方法和分析所采用的方法。我们用基于研究方法对现有成果进行分类总结和讨论最近的工作。单人和多人的人体姿态估计首先进行分别介绍，然后是深度学习对这些估计方法所采用的技术进行了比较分析，最后对此任务中所使用的主流数据集和指标进行讨论和比较。\\
	
	\noindent{\bf 关键点: }人体姿态估计;深度学习;计算机视觉
	\begin{multicols}{2}
		\section{引言}
		人体姿态估计广泛应用于人机交互、游戏、虚拟现实、视频监控、运动分析、医疗辅助等领域，是计算机视觉领域非常热门的研究课题\cite{DBLP:journals/corr/PapandreouZKTTB17}\cite{DBLP:conf/eccv/InsafutdinovPAA16}\cite{DBLP:conf/cvpr/CaoSWS17}\cite{wei2016convolutional}。人体姿态估计旨在从图像或视频中自动定位人体部位。在一个简单的例子中，如图\ref{a}所示，图像中只有一个人，或者给出了这个人的位置，需要使用一个人算法来定位人体的部分，比如头顶、颈部中心、左/右肘部\cite{chen2014articulated}\cite{martinez2017simple}\cite{chen2017adversarial}。在更一般的情况下,如图\ref{b}所示，在图像中人的数量和位置未知的情况下，进行多人姿态估计算法\cite{DBLP:conf/eccv/InsafutdinovPAA16}\cite{DBLP:conf/cvpr/CaoSWS17}\cite{pishchulin2016deepcut}。图像中所有的人体关键点位置都应该被检测出来，而属于同一个人的关键点应该被关联起来，即使是在拥挤的场景中。
		
		\begin{figure}[H]
			\centering
			\includegraphics[scale = 0.3]{1}
			\caption{单人姿态估计结果示例\cite{toshev2014deeppose}。}
			\label{a}
		\end{figure}
		
		\begin{figure}[H]
			\centering
			\includegraphics[scale = 0.3]{2}
			\caption{多人姿态估计结果示例\cite{DBLP:conf/cvpr/CaoSWS17}}
			\label{b}
		\end{figure}
	
		为了解决人体姿态估计问题，许多文献中提出了许多方法。手工标注的特征已经在早期的人体姿态估计工作中使用。这些手工标注的特征，如HOG(方向梯度直方图)\cite{yang2011articulated}\cite{yang2012articulated}\cite{wang2013beyond}\cite{6126309}\cite{eichner20122d}(图\ref{c})和Edgelet\cite{eichner2010we}，在确定身体各部位的准确位置方面不足。相比之下，基于深度学习的方法能够从元数据中提取更充分的特征。这些方法取得了良好的效果，并且在很大程度上优于现有的非深度方法。虽然深度学习在人体姿态估计领域的应用比较新，但在这方面已经开展了许多优秀的工作。在此本综述的目标是提供最先进的基于深度学习的二维(2D)人体姿态估计方法的全面概述。
		
		我们的调查所遵循的树形结构分类如图\ref{d}所示。对于当前的论文，我们选择了基于方法的分类
		\begin{figure}[H]
			\centering
			\includegraphics[scale = 0.3]{3}
			\caption{关键点检测的HOG特征示例}
			\label{c}
		\end{figure}
		\noindent 法。首先将所有的人体姿态估计方法分为两类:单人姿态估计方法和多人姿态估计方法。一方面，单人方法检测图像中某个人的姿势。由于位置信息已知，单人法的目标是找到该区域内的关键点位置，因此求解回归问题至关重要，其中关键点的数量隐式给出。另一方面，多人方法的目标是解决一个无约束问题，因为人的数量和位置是未知的。
		
		\begin{figure}[H]
			\centering
			\includegraphics[scale = 0.25]{4}
			\caption{估计方法分类综述}
			\label{d}
		\end{figure}
		
		根据预测关键点的方式，预测一个人的方法可以分为两种:基于直接回归的方法和基于热图的方法。前者利用输出特征图直接回归关键点，后者先生成热图(热图中的像素值表示关键点在该位置的存在概率)，根据热图预测关键点。多人方法可以根据其方法论分为两类:自顶向下方法和自底向上方法。自顶向下方法大致分为两步:人体检测和单人关键点估计。自底向上方法有类似的步骤，但顺序相反:第一步是定位图像中所有的关键点，第二步是根据它们所属的人对这些关键点进行分组。
		
		之前也有其他与姿态估计有关的综述。如Guo et al.\cite{guo2016deep}对深度学习方法进行了回顾，并将人体姿态估计作为其中的一部分，但他们关注的是深度学习在计算机视觉中的应用，只是对人体姿态估计方法进行了简单的总结。Poppe\cite{poppe2007vision}回顾了早期的基于视觉的人体运动分析方法。Liu等\cite{liu2015survey}研究了基于人体部位解析的人体姿态估计方法，但他们审查的大多数方法都是基于手工特征的。Zhang et al.\cite{zhang2016survey}和Gong et al.\cite{gong2016human}也对人体姿势进行了调查。但他们的调查并没有关注基于深度学习的方法。针对特定的人体部位，如手和头的姿态估计方法在参考文献\cite{murphy2008head}\cite{erol2007vision}中进行了综述。Asadi-Aghbolaghi等人\cite{asadi2017survey}调查了图像序列中基于深度学习的动作和手势识别方法，并讨论了应用于动作和手势识别的深度学习技术。

		
	
		\section{单人姿态检测方法}
		在给定人体位置的条件下，单人法估计人体在图像或视频中的姿态。一般情况下，在进行估计之前，先提供一个人的位置和大致的比例尺或一个人的边界框。早期的作品将人体部位建模为火柴棍(图\ref{e})，但最近的作品将其建模为关键关节，因为这些关节自然连接，位置更准确。基于深度学习的单人方法的目标是定位人体部位的关键点。单人姿态检测方法有两种典型的框架:(1)第一个框架直接从特征中回归关键点，我们称之为基于直接回归的框架。
		(2)另一种算法首先生成热图，通过热图推断关键点位置。我们称之为基于热图的框架。
		\begin{figure}[H]
			\centering
			\includegraphics[scale = 0.4]{5}
			\caption{人注释为火柴棍的例子\cite{ferrari2008progressive}}
			\label{e}
		\end{figure}
		\subsection{基于直接回归的框架}
		有几篇文章是基于直接回归框架的。Toshev和Szegedy\cite{toshev2014deeppose}提出了级联反应DNN回归因子直接预测人类关键点。然而，如果没有其他的过程，从特征图中直接学习映射是很困难的。carira等人\cite{carreira2016human}使用了自校正模型。通过反馈误差预测，逐步优化预测的关键点位置。Sun等人\cite{sun2017compositional}提出了一种结构感知方法，称为“组合姿态回归”。与其他相关工作不同，这种方法使用骨骼而不是关节重新参数化姿态表示，更原始、更稳定、更容易学习。骨骼之间的长期相互作用由成分损失函数编码。Luvizon等人\cite{luvizon2019human}提出Soft-argmax以完全可微的方式将热图转换为坐标。采用基于关键点误差距离的损失函数和基于上下文的结构进行端到端可训练网络，使其能够实现与最先进的基于热图的框架相比较的结果。
		\subsection{基于热力图的框架}
		如图\ref{f}所示，许多文章都采用了基于热图的框架。一些文章在他们的模型中利用了人类的先验知识。例如Chen和Yuille\cite{chen2014articulated}使用的是DCNN学习到的成对关系的图形模型(零件类型和成对零件关系)。在另一项研究中，Chen et al.\cite{chen2017adversarial}采用条件生成的训练策略，融合了人体的先验敌对的网络(GANs)\cite{goodfellow2014generative}。
		
		网络结构设计一直是基于深度学习方法的一个主题。卷积的姿势机器(CPM)\cite{wei2016convolutional}在多个阶段回归热图，并使用中间监督来避免消失梯度。Newell等人\cite{newell2016stacked}设计了一种新的网络结构，称为“堆叠沙漏”。重复的自底而上，自顶而下的处理与中间监督被证明是提高人体姿态检测性能的关键。Chu等人\cite{chu2017multi}基于堆叠沙漏建立了他们的基线模型。他们采用了一种多情境注意机制，使模型更稳健、更准确。他们还通过耦合沙漏剩余单元来改进堆叠沙漏的结构。
		
		二维和三维之间的关系(3D)关键点检测也进行了探讨。Martinez等人\cite{martinez2017simple}提出利用深度神经网络直接利用2D关键点预测3D关键点。实验结果表明，二维检测是造成人体三维姿态估计误差的主要原因之一。
		\subsection{讨论}
		基于直接回归的框架和基于热图的框架，哪个框架更好?早期的文章\cite{toshev2014deeppose}\cite{pfister2014deep}和近期的一些文章\cite{chen2017adversarial}\cite{goodfellow2014generative}都尝试直接回归关键点的坐标。关节位置的直接回归是高度非线性的，在映射学习上存在困难\cite{tompson2014joint}\cite{pfister2015flowing}。此外，它不能应用于多人案件(自底向上方法或单个检测框包含一个以上的人)。相比之下，基于热图的框架首先回归热图。热图可以可视化，以增强人类的理解和模拟更复杂的情况。但是，如果将这些特定的技术结合起来\cite{chen2017adversarial}，直接回归会更可靠，也有一些优点。当应用直接回归时，最终结果可以在不处理热图的情况下以端到端的方式获得。而且，它可以应用于3D场景，不需要太多的变化。此外，预测结果的精度依赖于热图分辨率，这需要较高的内存消耗。因此，对于这个问题没有一个绝对的结论，每个框架都有其优点和缺点。
	\end{multicols}
		
		
		\begin{figure}[H]
			\centering
			\includegraphics[scale = 0.36]{6}
			\caption{同一幅图分别基于热力图与关键点的例子。}
			\label{f}
		\end{figure}
		\begin{multicols}{2}
		\section{多人姿态检测方法}
		与单人检测方法相比，多人检测方法更困难，因为没有给出人员数量和位置信息。
		关键点检测和人的定位是该任务的两个核心问题。为了解决这两个问题，目前比较流行的方法有:(1)自顶而下方法和(2)自底而上方法。
		\subsection{自顶向下方法}
		自顶向下方法的第一步是检测给定图像中的所有人，然后在每个检测到的边界框中执行单个人的方法。图\ref{g}显示了自顶向下方法的说明。除了人的检测，自顶向下的方法有更多的过程，可能会利用整个图像的上下文信息。示例如图\ref{i}。
		\begin{figure}[H]
			\centering
			\includegraphics[scale = 0.63]{8}
			\caption{自上而下方法框架}
			\label{g}
		\end{figure}
		
		Toshev和Szegedy\cite{toshev2014deeppose}利用FLIC数据集\cite{sapp2013modec}提出了第一种基于深度学习的自顶向下方法。人体姿态估计是回归研究中的一个关键问题。首先利用基于人脸的身体检测器估计人体的大致位置，然后采用基于多级级联DNN的关节坐标回归算子直接回归关节坐标。在之前的工作\cite{radosavovic2018data}中探讨了数据增强。Radosavovic等人\cite{radosavovic2018data}利用全监督学习，利用所有可用的数据(有标记的和无标记的)来训练模型。这项工作证明，最先进的人体姿势探测器足够准确，可以应用自我训练技术来挑战现实世界的数据。
		
		有些研究者研究了人体检测和人体盒子对准问题。Fang等人\cite{fang2017rmpe}注意到，单人姿势估计对人体检测很敏感。为了解决这个问题，他们采用了对称空间变压器网络(SSTN)与平行的单人姿态估计(SPPE)提取高质量的单人区域。Mask R-CNN\cite{he2017mask}同时预测人的包围盒和人的关键点，通过共享ConvNet的特征使检测速度更快。此外,RoI对齐可以实现更精确的特征图裁剪方法。这项工作没有结合人类骨骼的先验。加入人类骨骼的先验信息可能会进一步提高Make R-CNN的准确性。
		
		还有一些研究集中在人体检测框内的关键点估计。例如，Iqbal和Gall\cite{iqbal2016multi}认为多人姿态估计是一个关节对人的关联问题。他们的方法的目的是解决遮挡问题。通过局部关联检测到的关键点，消除了同一检测框中多余的人员部件。这项工作基于\cite{martinez2017simple}，但是通过导入本地关联的机制执行得更快。Papandreou等人\cite{DBLP:journals/corr/PapandreouZKTTB17}提出了一种同时预测联合密集热图和位置偏移量的方法，将这两种输出集合起来，得到高度局域化的关键点位置。Chen等\cite{chen2018cascaded}提出了一种被称为级联金字塔网络的网络结构，它由两部分组成:GlobalNet和RefineNet。前者可以捕捉到良好的特征表示，而后者被用来处理准确例子。
		
		后处理方法已经在\cite{fang2017rmpe}中提出。数据驱动姿势非最大抑制在\cite{fang2017rmpe}中提出了(NMS)来解决遮挡问题，并使用姿态引导的提议生成器来进行数据增强。然而，严重的遮挡或误检仍然是该方法的一大挑战。\cite{DBLP:journals/corr/PapandreouZKTTB17}采用位姿评分和基于位姿的NMS方法消除假阳性，保持真阳性。
		\subsection{关于自顶向下方法的讨论}
		在自上而下的人体姿态估计中，人体探测器是否重要?自顶向下方法的第一步是人体检测。在人体姿态估计中最常用的人体探测器是基于Faster R-CNN结构的，因为它是一种高性能的现成检测器。更快的R-CNN有许多不同的基本网络(VGG\cite{simonyan2014very}， ResNet\cite{he2016deep}，和
		Inception- ResNet\cite{szegedy2017inception})和不同的扩展结构红外系统\cite{8099589})。这些变体具有不同程度的准确性、推断时间和计算复杂度。一般情况下，检测结果越准确，认为网络越复杂。因此，需要考虑准确性、消耗的内存和时间之间的权衡。
		
		一些工作比较了不同的人体检测器对人体姿态估计器的性能\cite{chen2018cascaded}。大多数工作结果表明，人体姿态估计的精度随着人体检测器的改进而提高。与此同时，在检测器性能较低的情况下，人体姿态估计器从性能较好的人体检测器获得较大增益。随着人体探测器平均精度的提高(AP)，人体姿态估计器的AP增长较慢。当人体探测器达到非常高的精度(许多高性能人体探测器的集合)时，其人体姿态估计网络的精度将无法再提高。可能的原因是，没有被人类检测器检测到的人也是人类姿态估计器的困难例子。
		
		换句话说，人体探测器在性能一般的时候很重要，但在已经达到高性能的时候就不重要了。当人体检测AP较高时，姿态估计器的增益很小，特别是当人体检测器已经足够准确时。
		
		非极大值抑制是抑制冗余检测的常用方法。该技术可应用于自顶向下人体姿态估计方法的两个阶段。对于人类检测，有两种基础方式:标准抑制方式和软抑制方式\cite{bodla1704improving}。软抑制方式降低了检测框评分，标准抑制方式对检测框评分。软抑制方式在\cite{chen2018cascaded}中性能更好，但计算复杂度与标准抑制方式相同，使其成为一种简单的提高人体检测的方法。基于部分的非极大值抑制\cite{burgos2013merging}\cite{chen2015parsing}\cite{chen2014detect}可以消除同一检测框中的人体骨架实例。参考文献提出的方法。\cite{burgos2013merging}通过在标准坐标系中用质心替换中间点，将时间和空间上的部分合并非极大值抑制。但该方法仅适用于人体火柴杆模型。过去的一项研究\cite{chen2018cascaded}提出了一个基于非极大值抑制的OKS，它考虑了人类实例之间关键点的相似性。\cite{fang2017rmpe}中提出的参数位姿非极大值抑制是数据驱动的，即所有参数都是从数据中学习而不是手动设置。该方法比\cite{burgos2013merging}中提出的方法快得多，但比\cite{chen2018cascaded}中的非极大值抑制方法复杂。
		\subsection{自底向上方法}
		与自顶向下的方法相比，自底向上的方法有相反的过程，如图\ref{h}所示。在第一阶段检测所有的身体部位(关键点)，然后在第二阶段将它们与人体实例关联。如图11所示。可以看到，自底向上方法的推断时间可能更快，因为它不需要分别检测每个人的姿势。示例如图\ref{j}。
		
		\begin{figure}[H]
			\centering
			\includegraphics[scale = 0.7]{9}
			\caption{自上而下方法框架}
			\label{h}
		\end{figure}
		
		Pishchulin等人\cite{pishchulin2016deepcut}提出了第一种基于深度学习的自下而上姿态估计方法。它们的形成过程通过解决一个成本最低的多切割问题来执行估计任务，该问题将关键点的候选点建模为顶点，关键点的候选点之间的关系建模为边。
		
		Insafutdinov等人\cite{DBLP:conf/eccv/InsafutdinovPAA16}]对\cite{pishchulin2016deepcut}进行了三个方面的改进:(1)他们使用的网络比\cite{pishchulin2016deepcut}的网络更深入，产生了更有效的身体部位建议。(2)新的图像条件成对，使关键点建议组合成可变数量的人实例成为可能。(3)改变了优化策略，提高了精度和速度。尽管与之前的版本\cite{pishchulin2016deepcut}相比已经取得了显著的改进，但深度切割\cite{DBLP:conf/eccv/InsafutdinovPAA16}在解决最小成本、多切割问题时仍然很慢。参考文献\cite{8099625}提出的方法进一步改进了参考文献\cite{DBLP:conf/eccv/InsafutdinovPAA16}提出的方法，简化了整体-部分关系图，并将相当一部分计算量转移到前馈网络上。
		
		Cao等人\cite{DBLP:conf/cvpr/CaoSWS17}提出了一种有效的方法，该方法使用非参数表示，称为部分亲和性字段(PAFs)。在热图和PAFs生成后，利用贪心算法生成人体实例。Zhu et al.\cite{zhu2017multi}对\cite{DBLP:conf/cvpr/CaoSWS17}进行了多次修改，取得了更好的成绩。这些修改包括一个更深层的网络结构和新架构的PAFs，它们有助于将这些子连接连接到一个损坏的父连接上。
		
		同时，在\cite{newell2017associative}中提出了一种用于监督卷积神经网络检测和分组任务的关联嵌入方法。该方法可以同时预测局部热图和标记热图。标记热图的值对于同一个人是相似的，而对于不同的人是不同的。
		\subsection{关于自底向上方法的讨论}
		重点的位置是首先要考虑的，在人体姿态估计中，位置对算法的性能影响很大。在目前的工作中，有三种方法来生成地面真实热图。第一个是在每个关键点\cite{DBLP:conf/cvpr/CaoSWS17}处设置二维高斯激活的热图。第二种方法是将圆内以关键点为圆心，半径为R (hyper参数)的所有位置像素值设为1，其他位置设为0\cite{DBLP:journals/corr/PapandreouZKTTB17}\cite{DBLP:conf/eccv/InsafutdinovPAA16}。当使用这种类型的热图时，预测位置偏移图可以更准确地定位关键点。第三种方法是生成一个热的二进制掩模，其中只有一个像素被标记为前景。当使用一个热的热图时使用softmax损失，因为它们鼓励一个单点被检测到\cite{he2017mask}。热图的最大激活(或热图执行在一些著作中选择了高斯滤波器)作为重点\cite{zhu2017multi}。另一项研究\cite{DBLP:journals/corr/PapandreouZKTTB17}也使用热图来投票决定关键点的最终位置。
		
		检测关联是自底向上方法中的一个重要步骤。Deepcut\cite{pishchulin2016deepcut}只使用CNN来学习外观特征，使用其他手工定义的几何特征来拟合logistic模型进行两两概率估计。而Deepercut\cite{DBLP:conf/eccv/InsafutdinovPAA16}将人工计算的特征改变为深度神经网络生成的学习特征，极大地提高了AP。两种方法都采用了几何特征的逻辑模型来模拟关节的亲和度。同时学习PAFs\cite{zhu2017multi}和联合嵌入\cite{newell2017associative}。这两种方法的性能比\cite{pishchulin2016deepcut}中报告的性能要好。这是因为深度神经网络具有更大的容量，并直接从数据中学习，它可以捕捉局部特征和全局上下文。
	\end{multicols}


\begin{figure}[H]
\centering
\includegraphics[scale = 0.33]{10}
\caption{自顶向下方法的示例。(a)输入图像，(b)人体检测器检测到两人，(c)裁剪后的单人图像，(d)单人姿态检测结果，(e)多人姿态检测结果。}
\label{i}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale = 0.36]{11}
	\caption{自底向上方法的示例。(a)输入图像，(b)所有人的关键点，(c)所有检测到的关键点连接起来，形成人的实例}
	\label{j}
\end{figure}
\begin{multicols}{2}
		\section{讨论}
		相关的方法已经在上面进行了回顾，但没有详细讨论各方法的共同特点和差异。在本节中，将讨论一些关键过程(表\ref{table1}中列出)，以揭示在这两种方法中什么是重要的。
		\subsection{数据增强}
		深度学习方法的性能高度依赖于数据输入。机器学习模型获得的数据越多，模型的有效性就越高。以往的研究大多利用数据增强来增强神经网络的泛化能力。用于人体姿态估计的简单而有效的数据增强技术包括裁剪、旋转、缩放和水平翻转输入图像。还有其他有前景的深度学习方法。使用未标记数据来训练网络是一个不发达的方向。数据蒸馏\cite{radosavovic2018data}是一种全监督学习方法，利用未标记数据进行数据增强。这一工作证明了相似和不同的未标记数据都是有用和有效的姿态估计。
		\subsection{数据预处理}
		数据集中的训练数据大小不一，使得网络很难从不均匀的数据中学习。为了使输入一致，图像总是在训练过程中调整大小。图像大小调整有两个重要因素:比例和绝对大小。在人体姿态估计任务中，人体检测盒被扩展到一个固定的比例，而不失真的图像，因为数据分布保持在这种方式。一个更大的训练图像总是可以为网络带来收益。一种可能的解释是，输入越大，分辨率越高，从而为网络提供更详细的信息。输入大小的比例也会影响训练结果。通常，调整后的图像的宽度和高度是相同的。然而，，宽度较短的输入图像AP值略有下降，因为数据集中大多数人的宽度都较短。大的输入图像在训练阶段占用更多的内存，同时能带来更好的增益。
		\subsection{不同网络结构的比较}
		网络设计是深度学习的基础工作。近年来针对分类任务提出了大量的网络结构\cite{xie2017aggregated}\cite{huang2017densely}。然后这些结构被转移到其他任务，如目标检测，图像分割和人体姿态估计。然而，这些网络不适合直接应用于人体姿态估计，因为需要更高分辨率的特征图来获得更精确的结果。为了解决这个问题，设计了两个结构来执行所需的过程。第一个是hole算法(也叫atrous convolution或dilation convolution)\cite{chen2017deeplab}，它可以使各层在保持输出分辨率固定的同时有效地增加接收场。二是上采样，提高了输入特征图的特殊分辨率。后一种算法在分割任务时性能更好，但占用更多的GPU内存。这两种技术都在对图像进行裁剪时使用，得到合适的特征图大小。
		
		输出的步幅是另一个需要考虑的因素，因为在相同深度下，较小的步幅通常消耗更多的存储空间，但输出的热图分辨率更高。在之前的大部分作品中，最终的输出步幅都是8。在\cite{newell2017associative}中，步幅8网络已被证明可以取得与步幅4网络相似的结果。而\cite{newell2017associative}为单人姿态估计，在将检测结果发送到网络之前会调整大小，因此是否需要更小的步幅还在探索中。
		
		此外，与分类检测任务相比，人体姿态估计对关键点的位置更加敏感。为此，许多作品\cite{newell2017associative}\cite{zhu2017multi}都采用了浅层和深层之间的跳跃式连接。浅层由于分辨率高，包含更多的局部信息，而深层包含更多的语义信息。通过将本地信息和语义信息结合起来，跳过连接对这项任务有好处。
		
		有效接收野的大小也是设计良好网络的关键因素。接收野应该足够大，足以覆盖一个人的整个身体，这样所有的上下文信息都可以被包括在人体关键点检测中\cite{newell2017associative}\cite{zhu2017multi}。
		
		此外，Zhong等人\cite{zhong2018practical}提出了一种利用Q-learning自动设计高性能网络块的方法，应用于特定的人体姿态检测模块中。
		\subsection{自顶向下与自底向上}
		如前所述，近年来，深度学习方法已经探索了自底而上和自顶而下的方法。然而，哪种方法比另一种更好还有待确定，因为在实际应用程序中要考虑多个方面。精度和速度是多人姿态估计评价的两个关键因素。
		
		\textbf{准确度}:COCO 2017关键点的冠军\cite{DBLP:conf/cvpr/CaoSWS17}和AI挑战者Human的冠军\cite{chen2018cascaded}
		骨骼系统关键点挑战采用了自顶向下的管道。而\cite{newell2017associative}报道自底而上的管道在融合多尺度结果进行测试时也能达到类似的精度。在考虑自底向上管道的情况下，人的尺度变化会给人体姿态估计带来困难，因为网络无法从图像中学习到一致的特征。另一个需要注意的事实是，输出特征图分辨率和网络容量是相互制约的。
		
		\textbf{速度}:自顶而下流水线中每个人的姿势是逐个估计的，随着人数的增加消耗线性时间。相反，在自底向上的管道中，图像只通过网络一次。当图像进行前向传播时，由于当前网络总是非常深，它总是需要更多的时间。但是，如果方法设计得当，分组时间可以非常短(9人分组时间为0.58 ms)。因此，在自底向上框架中更快的速度是可能实现的。
		\subsection{人体姿态估计其他技巧}
		大部分的技巧在上面都有说明，但是在最近的作品中还有其他的技巧。例如，在裁判中使用的中间监督。\cite{zhu2017multi}已经被证明在训练一个更好的网络是有效的，因为它迫使网络从较浅的层学习特征，并防止消失的梯度。
		
		多任务学习提高了模型在检测任务\cite{ren2015faster}和关键点检测任务中的性能，因为当任务相似时，网络可以学习到更强的特征表示。
		
		另一个技巧只适用于自底向上的管道。采用单人关键点检测模型对自底向上的网络模型进行改进，虽然降低了检测速度，但在精度上有了很大的提高。
	\end{multicols}


\begin{table}[H]
	\centering
	\caption{关键程序的列表}
	\begin{tabular}{lllll}
		\hline
		关键程序                                      & \multicolumn{1}{c}{方法} & 单人      & 自顶向下    & 自底向上    \\ \hline
		\multicolumn{1}{r}{\multirow{2}{*}{数据增强}} & 传统:裁剪、旋转、缩放和水平翻转       & $\surd$ & $\surd$ & $\surd$ \\ \cline{2-5} 
		\multicolumn{1}{r}{}                      & 使用未标记数据:数据蒸馏           & $\surd$ & $\surd$ &         \\ \hline
		数据预处理                                     & 不失真调整图片大小              & $\surd$ & $\surd$ & $\surd$ \\ \hline
		\multirow{6}{*}{网络设计}                     & 上采样                  & $\surd$ & $\surd$ & $\surd$ \\
		& 输出步幅\textless{}=8      &         &         &         \\
		& 跳越连接                   &         &         &         \\
		& 大的有效感受野                &         &         &         \\
		& 自动搜寻法                  &         &         &         \\ \hline
		\multirow{2}{*}{后处理}                      & 检测NMS                  &         & $\surd$ &         \\ \cline{2-5} 
		& 骨架NMS                  &         & $\surd$ & $\surd$ \\ \hline
	\end{tabular}
	\label{table1}
\end{table}

	\begin{multicols}{2}
		\section{指标和数据集}
		\subsection{数据集}
		人体姿态估计已被研究多年。然而，由于人体姿势各不相同，因此很难为这项任务创建一个通用的数据集。为了逐步解决估计问题，数据集的数量和复杂度都呈递增趋势。人体姿势数据集列表如表\ref{table2}所示和这些数据集的一些样本显示在图\ref{q}所示。早期的数据集包含背景相对简单的图像。然而，基于深度学习的方法并不适合这些数据集，因为图像数量太少，不适合训练。基于深度学习的方法中常用的数据集有MSCOCO\cite{lin2014microsoft}， MPII\cite{andriluka20142d}， LSP\cite{johnson2010clustered}，FLIC\cite{sapp2013modec}， PoseTrack\cite{Andriluka2018PoseTrackAB}和AI Challenger\cite{Wu2017AIC}在更复杂的场景中包含更多的图像。LSP和FLIC数据集相对较小，只包含特定类别的活动。LSP数据集中的图像来自体育场景。FLIC数据集是从好莱坞电影中收集的。最新的数据集，如MSCOCO和AI Challenger在规模和类别数量上都更大。
		
		
		\subsection{指标}
		人体姿态估计的性能评估是一个困难的问题，因为需要考虑很多因素。在早期工作中使用的评估指标是正确估计的身体部位百分比(PCP)\cite{ferrari2008progressive}，评估关键点预测结果。另一个广泛使用的关键点检测指标是PCK\cite{yang2011articulated}及其变体PCKh。在这两个指标中，一个指标是处于位于真实值关键点的周围$\alpha\cdot max(w,h)$像素，其中w和h是人的边界框的高度和宽度),另一个最近的指标包括目标关键点相似度(OKS)及其AP，该方法不仅考虑了规模，还引入了逐点常数来控制衰减。
	\end{multicols}

\begin{figure}[H]
	\centering
	\includegraphics[scale = 0.5]{12}
	\caption{不同数据集的例子}
	\label{q}
\end{figure}

\begin{table}[H]
	\centering
	\caption{人体姿态估计数据集}
	\begin{tabular}{lllll}
		\hline
		年份                                        & \multicolumn{1}{c}{数据集}            & 大小              & 类型                   & 描述数量                    \\ \hline
		\multicolumn{1}{c}{\multirow{2}{*}{2008}} & \multirow{2}{*}{Buffy}             & 472帧训练          & \multirow{2}{*}{上半身} & \multirow{2}{*}{6个身体部位} \\
		\multicolumn{1}{c}{}                      &                                    & 276帧测试          &                      &                         \\ \hline
		\multirow{2}{*}{2010}                     & \multirow{2}{*}{LSP}               & 1000张训练         & \multirow{2}{*}{全身}  & \multirow{2}{*}{14个关键点} \\
		&                                    & 1000张测试         &                      &                         \\ \hline
		\multirow{2}{*}{2013}                     & \multirow{2}{*}{FLIC}              & 3987张训练         & \multirow{2}{*}{上半身} & \multirow{2}{*}{10个关键点} \\
		&                                    & 1016张测试         &                      &                         \\ \hline
		\multirow{2}{*}{2014}                     & \multirow{2}{*}{Parse}             & 100张训练          & \multirow{2}{*}{全身}  & \multirow{2}{*}{14个关键点} \\
		&                                    & 205张测试          &                      &                         \\ \hline
		\multirow{2}{*}{2014}                     & \multirow{2}{*}{MPII Human pose}   & 410个活动          & \multirow{2}{*}{全身}  & \multirow{2}{*}{16个关键点} \\
		&                                    & 25000张图片        &                      &                         \\ \hline
		\multirow{2}{*}{2014}                     & \multirow{2}{*}{Poses in the wild} & 30个视频序列         & \multirow{2}{*}{上半身} & \multirow{2}{*}{5个关键点}  \\
		&                                    & 900帧图片          &                      &                         \\ \hline
		\multirow{3}{*}{2014}                     & \multirow{3}{*}{MSCOCO}            & 115000张图片训练     & \multirow{3}{*}{全身}  & \multirow{3}{*}{17个关键点} \\
		&                                    & 5000张图片验证       &                      &                         \\
		&                                    & 20000张图片测试实验    &                      &                         \\ \hline
		\multirow{3}{*}{2017}                     & \multirow{3}{*}{AI Challenger}     & 210000张图片训练     & \multirow{3}{*}{全身}  & \multirow{3}{*}{14个关键点} \\
		&                                    & 30000张图片验证      &                      &                         \\
		&                                    & 60000张图片测试      &                      &                         \\ \hline
		\multirow{4}{*}{2017}                     & \multirow{4}{*}{Pose Track}        & 514个视频包含66374帧图 & \multirow{4}{*}{全身}  & \multirow{4}{*}{15个关键点} \\
		&                                    & 300个视频训练        &                      &                         \\
		&                                    & 50个视频验证         &                      &                         \\
		&                                    & 208个视频测试        &                      &                         \\ \hline
	\end{tabular}
	\label{table2}
\end{table}



\newpage
%\nocite{*}


\bibliographystyle{cjc}
\bibliography{example}
\end{document}